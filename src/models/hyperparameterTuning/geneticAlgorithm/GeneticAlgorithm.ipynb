 {
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithm Hyperparameter Tuning for Batik Classification\n",
    "\n",
    "This notebook implements a custom Genetic Algorithm for hyperparameter tuning for the batik classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Third-party packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflowjs as tfjs\n",
    "from keras.layers import TFSMLayer\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    GlobalAveragePooling2D,\n",
    "    Dense,\n",
    "    Dropout\n",
    ")\n",
    "from tensorflow.keras.applications import InceptionV3, MobileNetV2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import (\n",
    "    ImageDataGenerator,\n",
    "    load_img,\n",
    "    img_to_array\n",
    ")\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    Callback\n",
    ")\n",
    "\n",
    "# Hilangkan warning TensorFlow dan Python\n",
    "import warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\"âœ… TensorFlow mendeteksi GPU (CUDA):\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"  - {gpu.name}\")\n",
    "else:\n",
    "    print(\"âš ï¸ TensorFlow TIDAK mendeteksi GPU. Model berjalan di CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('dataset_split', 'train')\n",
    "val_dir = os.path.join('dataset_split', 'val')\n",
    "test_dir = os.path.join('dataset_split', 'test')\n",
    "\n",
    "# Fungsi untuk menghitung jumlah file per kelas dalam sebuah direktori\n",
    "def count_images_per_class(directory):\n",
    "    return {\n",
    "        cls: len(os.listdir(os.path.join(directory, cls)))\n",
    "        for cls in os.listdir(directory)\n",
    "        if os.path.isdir(os.path.join(directory, cls))\n",
    "    }\n",
    "    \n",
    "# Hitung jumlah gambar per kelas\n",
    "train_counts = count_images_per_class(train_dir)\n",
    "val_counts = count_images_per_class(val_dir)\n",
    "test_counts = count_images_per_class(test_dir)\n",
    "total_gambar = sum(train_counts.values()) + sum(val_counts.values()) + sum(test_counts.values())\n",
    "\n",
    "# Gabungkan ke dalam DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Train': train_counts,\n",
    "    'Validation': val_counts,\n",
    "    'Test': test_counts\n",
    "}).T.fillna(0).astype(int).T  # Transpose agar kelas sebagai indeks\n",
    "\n",
    "\n",
    "print(f\"Total gambar : {total_gambar}\")\n",
    "# Tampilkan sebagai tabel\n",
    "print(\"\\nSebaran Data per Kelas:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 4\n",
    "SEED = 42\n",
    "NUM_CLASSES = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,                # Normalisasi piksel gambar dari 0-255 menjadi 0-1\n",
    "    rotation_range=20,            # Rotasi gambar acak hingga 20 derajat\n",
    "    zoom_range=0.2,               # Zoom acak hingga 20% untuk mensimulasikan perbedaan jarak\n",
    "    width_shift_range=0.2,        # Geser gambar secara horizontal hingga 20% lebar gambar\n",
    "    height_shift_range=0.2,       # Geser gambar secara vertikal hingga 20% tinggi gambar\n",
    "    shear_range=0.15,             # Distorsi gambar secara miring (shear)\n",
    "    horizontal_flip=True,         # Membalik gambar secara horizontal (misalnya daun kiri dan kanan)\n",
    "    brightness_range=[0.8, 1.2],  # Variasi pencahayaan gambar\n",
    "    fill_mode='nearest'           # Isi area kosong hasil transformasi dengan piksel terdekat\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,  # Folder berisi data latih\n",
    "    target_size = IMG_SIZE,         # Ukuran gambar diubah menjadi 224x224\n",
    "    batch_size = BATCH_SIZE,        # Jumlah gambar per batch\n",
    "    class_mode = 'categorical',       # Label dalam format one-hot (karena klasifikasi multi-kelas)\n",
    "    shuffle = True,                   # Acak data untuk melatih model dengan lebih baik\n",
    "    seed = SEED                         # Seed untuk konsistensi hasil saat diacak\n",
    ")\n",
    "\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,  # Folder validasi\n",
    "    target_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False,                  # Tidak diacak agar evaluasi konsisten\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,   # Folder pengujian\n",
    "    target_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False,                  # Tidak diacak agar prediksi bisa dibandingkan langsung\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, GlobalAveragePooling2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "# Callback untuk progress log\n",
    "class TuningCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, tuner_name):\n",
    "        super().__init__()\n",
    "        self.tuner_name = tuner_name\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metrics_str = \" | \".join([f\"{k}: {v:.4f}\" for k, v in logs.items()])\n",
    "        print(f\"âœ¨ {self.tuner_name} - Epoch {epoch + 1} â€” {metrics_str}\")\n",
    "\n",
    "# =========== GENETIC ALGORITHM IMPLEMENTATION ===========\n",
    "class GeneticAlgorithm:\n",
    "    def __init__(self, population_size=10, generations=20, mutation_rate=0.1, crossover_rate=0.8):\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.best_individual = None\n",
    "        self.best_fitness = 0\n",
    "        self.history = []\n",
    "        \n",
    "    def create_individual(self) -> Dict[str, Any]:\n",
    "        \"\"\"Create a random individual (hyperparameter set)\"\"\"\n",
    "        return {\n",
    "            'learning_rate': random.choice([1e-4, 3e-4, 1e-3, 3e-3, 1e-2]),\n",
    "            'optimizer': random.choice(['adam', 'rmsprop', 'sgd']),\n",
    "            'dense_units': random.choice([64, 128, 256, 384, 512]),\n",
    "            'dropout_rate': random.choice([0.0, 0.1, 0.2, 0.3, 0.4, 0.5]),\n",
    "            'add_conv_layer': random.choice([True, False]),\n",
    "            'conv_filters': random.choice([32, 64, 96, 128])\n",
    "        }\n",
    "    \n",
    "    def create_population(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Create initial population\"\"\"\n",
    "        return [self.create_individual() for _ in range(self.population_size)]\n",
    "    \n",
    "    def build_model_from_individual(self, individual: Dict[str, Any]) -> tf.keras.Model:\n",
    "        \"\"\"Build model from individual hyperparameters\"\"\"\n",
    "        # Load pre-trained MobileNetV2 dengan freezing\n",
    "        base_model = MobileNetV2(\n",
    "            input_shape=(*IMG_SIZE, 3),\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "        \n",
    "        # Freeze semua layer pada base model\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(base_model)\n",
    "        \n",
    "        # Tambahkan ConvLayer (opsional)\n",
    "        if individual['add_conv_layer']:\n",
    "            model.add(Conv2D(individual['conv_filters'], (3, 3), activation='relu', padding='same'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "        # GlobalAveragePooling2D untuk flatten feature map\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        \n",
    "        # Dense layers\n",
    "        model.add(Dense(individual['dense_units'], activation='relu'))\n",
    "        \n",
    "        # Dropout untuk regularisasi\n",
    "        if individual['dropout_rate'] > 0:\n",
    "            model.add(Dropout(individual['dropout_rate']))\n",
    "        \n",
    "        # Layer output\n",
    "        model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "        \n",
    "        # Kompilasi dengan hyperparameter\n",
    "        if individual['optimizer'] == 'adam':\n",
    "            optimizer = Adam(learning_rate=individual['learning_rate'])\n",
    "        elif individual['optimizer'] == 'rmsprop':\n",
    "            optimizer = RMSprop(learning_rate=individual['learning_rate'])\n",
    "        else:\n",
    "            optimizer = SGD(learning_rate=individual['learning_rate'], momentum=0.9)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def evaluate_individual(self, individual: Dict[str, Any]) -> float:\n",
    "        \"\"\"Evaluate individual by training model and returning validation accuracy\"\"\"\n",
    "        try:\n",
    "            model = self.build_model_from_individual(individual)\n",
    "            \n",
    "            # Callbacks\n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=3,\n",
    "                restore_best_weights=True,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            # Train model\n",
    "            history = model.fit(\n",
    "                train_generator,\n",
    "                validation_data=val_generator,\n",
    "                epochs=10,  # Shorter training for faster evaluation\n",
    "                callbacks=[early_stopping],\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            # Return best validation accuracy\n",
    "            best_val_acc = max(history.history['val_accuracy'])\n",
    "            return best_val_acc\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating individual: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def select_parents(self, population: List[Dict[str, Any]], fitness_scores: List[float]) -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
    "        \"\"\"Select parents using tournament selection\"\"\"\n",
    "        tournament_size = 3\n",
    "        \n",
    "        # Select first parent\n",
    "        tournament1 = random.sample(list(enumerate(population)), tournament_size)\n",
    "        parent1_idx = max(tournament1, key=lambda x: fitness_scores[x[0]])[0]\n",
    "        \n",
    "        # Select second parent\n",
    "        tournament2 = random.sample(list(enumerate(population)), tournament_size)\n",
    "        parent2_idx = max(tournament2, key=lambda x: fitness_scores[x[0]])[0]\n",
    "        \n",
    "        return population[parent1_idx], population[parent2_idx]\n",
    "    \n",
    "    def crossover(self, parent1: Dict[str, Any], parent2: Dict[str, Any]) -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
    "        \"\"\"Perform crossover between two parents\"\"\"\n",
    "        if random.random() > self.crossover_rate:\n",
    "            return parent1, parent2\n",
    "        \n",
    "        child1 = copy.deepcopy(parent1)\n",
    "        child2 = copy.deepcopy(parent2)\n",
    "        \n",
    "        # Single point crossover for each parameter\n",
    "        for key in parent1.keys():\n",
    "            if random.random() < 0.5:\n",
    "                child1[key], child2[key] = child2[key], child1[key]\n",
    "        \n",
    "        return child1, child2\n",
    "    \n",
    "    def mutate(self, individual: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Mutate individual with some probability\"\"\"\n",
    "        mutated = copy.deepcopy(individual)\n",
    "        \n",
    "        for key in mutated.keys():\n",
    "            if random.random() < self.mutation_rate:\n",
    "                if key == 'learning_rate':\n",
    "                    mutated[key] = random.choice([1e-4, 3e-4, 1e-3, 3e-3, 1e-2])\n",
    "                elif key == 'optimizer':\n",
    "                    mutated[key] = random.choice(['adam', 'rmsprop', 'sgd'])\n",
    "                elif key == 'dense_units':\n",
    "                    mutated[key] = random.choice([64, 128, 256, 384, 512])\n",
    "                elif key == 'dropout_rate':\n",
    "                    mutated[key] = random.choice([0.0, 0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "                elif key == 'add_conv_layer':\n",
    "                    mutated[key] = random.choice([True, False])\n",
    "                elif key == 'conv_filters':\n",
    "                    mutated[key] = random.choice([32, 64, 96, 128])\n",
    "        \n",
    "        return mutated\n",
    "    \n",
    "    def evolve(self) -> Dict[str, Any]:\n",
    "        \"\"\"Run genetic algorithm\"\"\"\n",
    "        print(f\"ðŸš€ Memulai Genetic Algorithm dengan {self.population_size} individu dan {self.generations} generasi\")\n",
    "        \n",
    "        # Create initial population\n",
    "        population = self.create_population()\n",
    "        \n",
    "        for generation in range(self.generations):\n",
    "            print(f\"\\nðŸ”„ Generasi {generation + 1}/{self.generations}\")\n",
    "            \n",
    "            # Evaluate all individuals\n",
    "            fitness_scores = []\n",
    "            for i, individual in enumerate(population):\n",
    "                print(f\"  Evaluating individual {i+1}/{len(population)}...\")\n",
    "                fitness = self.evaluate_individual(individual)\n",
    "                fitness_scores.append(fitness)\n",
    "                print(f\"    Fitness: {fitness:.4f}\")\n",
    "            \n",
    "            # Update best individual\n",
    "            best_idx = np.argmax(fitness_scores)\n",
    "            if fitness_scores[best_idx] > self.best_fitness:\n",
    "                self.best_fitness = fitness_scores[best_idx]\n",
    "                self.best_individual = copy.deepcopy(population[best_idx])\n",
    "                print(f\"  ðŸŽ‰ New best fitness: {self.best_fitness:.4f}\")\n",
    "            \n",
    "            # Record history\n",
    "            self.history.append({\n",
    "                'generation': generation + 1,\n",
    "                'best_fitness': max(fitness_scores),\n",
    "                'avg_fitness': np.mean(fitness_scores),\n",
    "                'best_individual': copy.deepcopy(population[best_idx])\n",
    "            })\n",
    "            \n",
    "            # Create new population\n",
    "            new_population = []\n",
    "            \n",
    "            # Elitism: keep best individual\n",
    "            new_population.append(copy.deepcopy(population[best_idx]))\n",
    "            \n",
    "            # Generate rest of population through selection, crossover, and mutation\n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1, parent2 = self.select_parents(population, fitness_scores)\n",
    "                child1, child2 = self.crossover(parent1, parent2)\n",
    "                \n",
    "                child1 = self.mutate(child1)\n",
    "                child2 = self.mutate(child2)\n",
    "                \n",
    "                new_population.extend([child1, child2])\n",
    "            \n",
    "            # Trim to population size\n",
    "            population = new_population[:self.population_size]\n",
    "            \n",
    "            print(f\"  Best fitness this generation: {max(fitness_scores):.4f}\")\n",
    "            print(f\"  Average fitness: {np.mean(fitness_scores):.4f}\")\n",
    "        \n",
    "        print(f\"\\nðŸ† Genetic Algorithm selesai!\")\n",
    "        print(f\"Best fitness achieved: {self.best_fitness:.4f}\")\n",
    "        print(f\"Best individual: {self.best_individual}\")\n",
    "        \n",
    "        return self.best_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== RUN GENETIC ALGORITHM ===========\n",
    "\n",
    "# Buat direktori untuk menyimpan hasil tuning\n",
    "project_dir = \"hyperparameter_tuning_genetic_results\"\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "# Initialize genetic algorithm\n",
    "ga = GeneticAlgorithm(\n",
    "    population_size=8,  # Smaller population for faster execution\n",
    "    generations=10,     # Fewer generations for demonstration\n",
    "    mutation_rate=0.1,\n",
    "    crossover_rate=0.8\n",
    ")\n",
    "\n",
    "# Run genetic algorithm\n",
    "best_hyperparameters = ga.evolve()\n",
    "\n",
    "print(\"\\n==== HYPERPARAMETER TERBAIK ====\")\n",
    "for key, value in best_hyperparameters.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train final model with best hyperparameters\n",
    "print(\"\\n==== LATIH MODEL FINAL DENGAN HYPERPARAMETER TERBAIK ====\")\n",
    "\n",
    "# Build model with best hyperparameters\n",
    "best_model = ga.build_model_from_individual(best_hyperparameters)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Callbacks for final training\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Train final model\n",
    "history = best_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        ModelCheckpoint('best_genetic_model.keras', save_best_only=True, monitor='val_accuracy'),\n",
    "        reduce_lr\n",
    "    ],\n",
    "    class_weight=class_weights_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save best model\n",
    "best_model.save('final_genetic_model.keras')\n",
    "print(\"Model final telah disimpan sebagai 'final_genetic_model.keras'\")\n",
    "\n",
    "# Evaluate model on test set\n",
    "print(\"\\n==== EVALUASI MODEL PADA TEST SET ====\")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = best_model.evaluate(test_generator)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize genetic algorithm progress\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot fitness evolution\n",
    "plt.subplot(1, 3, 1)\n",
    "generations = [h['generation'] for h in ga.history]\n",
    "best_fitness = [h['best_fitness'] for h in ga.history]\n",
    "avg_fitness = [h['avg_fitness'] for h in ga.history]\n",
    "\n",
    "plt.plot(generations, best_fitness, 'b-', label='Best Fitness', linewidth=2)\n",
    "plt.plot(generations, avg_fitness, 'r--', label='Average Fitness', linewidth=2)\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Fitness (Validation Accuracy)')\n",
    "plt.title('Genetic Algorithm Evolution')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot training history\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('genetic_algorithm_results.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"Genetic algorithm results telah disimpan sebagai 'genetic_algorithm_results.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of genetic algorithm results\n",
    "print(\"\\n==== ANALISIS HASIL GENETIC ALGORITHM ====\")\n",
    "print(f\"Total generations: {len(ga.history)}\")\n",
    "print(f\"Population size: {ga.population_size}\")\n",
    "print(f\"Mutation rate: {ga.mutation_rate}\")\n",
    "print(f\"Crossover rate: {ga.crossover_rate}\")\n",
    "print(f\"Best fitness achieved: {ga.best_fitness:.4f}\")\n",
    "\n",
    "print(\"\\nEvolution of best fitness:\")\n",
    "for i, record in enumerate(ga.history):\n",
    "    print(f\"Generation {record['generation']}: {record['best_fitness']:.4f}\")\n",
    "\n",
    "print(\"\\nComparison with other methods:\")\n",
    "print(\"Genetic Algorithm advantages:\")\n",
    "print(\"- Can find good solutions with fewer evaluations\")\n",
    "print(\"- Maintains diversity in search space\")\n",
    "print(\"- Can escape local optima through mutation\")\n",
    "print(\"- More efficient than GridSearch for large search spaces\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}