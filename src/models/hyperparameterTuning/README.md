# Hyperparameter Tuning Methods for Batik Classification

This directory contains three different hyperparameter tuning approaches for the batik classification model:

## ğŸ“ Directory Structure

```
hyperparameterTuning/
â”œâ”€â”€ randomSearch/
â”‚   â””â”€â”€ RandomSearch.ipynb          # Random Search implementation
â”œâ”€â”€ gridSearch/
â”‚   â””â”€â”€ GridSearch.ipynb            # Grid Search implementation
â”œâ”€â”€ geneticAlgorithm/
â”‚   â””â”€â”€ GeneticAlgorithm.ipynb      # Genetic Algorithm implementation
â””â”€â”€ README.md                       # This file
```

## ğŸ” Hyperparameter Tuning Methods

### 1. Random Search (`randomSearch/RandomSearch.ipynb`)

**What it does:**
- Randomly samples hyperparameter combinations from the search space
- Uses Keras Tuner's `RandomSearch` implementation
- Stops after a specified number of trials

**Advantages:**
- âœ… Fast and efficient
- âœ… Good for high-dimensional search spaces
- âœ… Can find good solutions quickly
- âœ… Less likely to get stuck in local optima

**Disadvantages:**
- âŒ May miss optimal combinations
- âŒ No guarantee of finding the best solution
- âŒ Results can be inconsistent between runs

**Best for:** Quick exploration of hyperparameter space, when you have limited time

---

### 2. Grid Search (`gridSearch/GridSearch.ipynb`)

**What it does:**
- Systematically tries ALL possible combinations of hyperparameters
- Uses Keras Tuner's `GridSearch` implementation
- Exhaustive search through the parameter space

**Advantages:**
- âœ… Guaranteed to find the optimal solution (within the grid)
- âœ… Reproducible results
- âœ… Systematic and thorough
- âœ… Good for small search spaces

**Disadvantages:**
- âŒ Extremely slow for large search spaces
- âŒ Exponential growth with parameter count
- âŒ Computationally expensive
- âŒ May not scale well

**Best for:** Small search spaces, when you need guaranteed optimal results

---

### 3. Genetic Algorithm (`geneticAlgorithm/GeneticAlgorithm.ipynb`)

**What it does:**
- Implements a custom genetic algorithm for hyperparameter optimization
- Uses evolutionary principles: selection, crossover, mutation
- Maintains a population of hyperparameter sets

**Advantages:**
- âœ… Can find good solutions with fewer evaluations
- âœ… Maintains diversity in search space
- âœ… Can escape local optima through mutation
- âœ… More efficient than GridSearch for large spaces
- âœ… Inspired by biological evolution

**Disadvantages:**
- âŒ More complex implementation
- âŒ Requires tuning of genetic parameters (mutation rate, crossover rate)
- âŒ No guarantee of finding global optimum
- âŒ Results can vary between runs

**Best for:** Large search spaces, when you want efficient exploration

---

## ğŸ¯ Hyperparameters Being Tuned

All three methods optimize the same hyperparameters:

1. **Learning Rate**: `[1e-4, 3e-4, 1e-3, 3e-3, 1e-2]`
2. **Optimizer**: `['adam', 'rmsprop', 'sgd']`
3. **Dense Units**: `[64, 128, 256, 384, 512]`
4. **Dropout Rate**: `[0.0, 0.1, 0.2, 0.3, 0.4, 0.5]`
5. **Add Conv Layer**: `[True, False]`
6. **Conv Filters**: `[32, 64, 96, 128]`

## ğŸ“Š Comparison Table

| Method | Speed | Completeness | Scalability | Best Use Case |
|--------|-------|--------------|-------------|---------------|
| **Random Search** | âš¡ Fast | ğŸ” Partial | ğŸ“ˆ Good | Quick exploration |
| **Grid Search** | ğŸŒ Slow | âœ… Complete | ğŸ“‰ Poor | Small spaces |
| **Genetic Algorithm** | âš¡âš¡ Medium | ğŸ” Partial | ğŸ“ˆğŸ“ˆ Excellent | Large spaces |

## ğŸš€ How to Use

1. **Choose your method** based on your needs:
   - Need quick results? â†’ Random Search
   - Small search space? â†’ Grid Search  
   - Large search space? â†’ Genetic Algorithm

2. **Run the notebook** for your chosen method:
   ```bash
   cd src/models/hyperparameterTuning/[method_name]
   jupyter notebook [MethodName].ipynb
   ```

3. **Monitor the results** and compare performance

## ğŸ“ˆ Expected Performance

- **Random Search**: Usually finds 80-90% of optimal performance in 20-30 trials
- **Grid Search**: Finds optimal solution but may take 100+ trials
- **Genetic Algorithm**: Usually finds 85-95% of optimal performance in 10-20 generations

## ğŸ”§ Customization

Each notebook can be customized by modifying:
- Population size (Genetic Algorithm)
- Number of trials (Random/Grid Search)
- Search space parameters
- Training epochs per trial
- Callback configurations

## ğŸ“ Notes

- All methods use the same model architecture (MobileNetV2 + custom layers)
- All methods use the same dataset and data augmentation
- Results are saved in separate directories for each method
- Training history and visualizations are generated for each method

## ğŸ¯ Recommendations

- **Start with Random Search** for initial exploration
- **Use Grid Search** if you have a small, well-defined search space
- **Try Genetic Algorithm** for complex, high-dimensional optimization problems
- **Compare results** from multiple methods to ensure robustness 