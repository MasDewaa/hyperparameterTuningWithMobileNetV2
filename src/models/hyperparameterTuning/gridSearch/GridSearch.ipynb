 {
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch Hyperparameter Tuning for Batik Classification\n",
    "\n",
    "This notebook implements GridSearch hyperparameter tuning for the batik classification model using Keras Tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Third-party packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflowjs as tfjs\n",
    "from keras.layers import TFSMLayer\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    GlobalAveragePooling2D,\n",
    "    Dense,\n",
    "    Dropout\n",
    ")\n",
    "from tensorflow.keras.applications import InceptionV3, MobileNetV2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import (\n",
    "    ImageDataGenerator,\n",
    "    load_img,\n",
    "    img_to_array\n",
    ")\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    Callback\n",
    ")\n",
    "\n",
    "# Hilangkan warning TensorFlow dan Python\n",
    "import warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\"‚úÖ TensorFlow mendeteksi GPU (CUDA):\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"  - {gpu.name}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è TensorFlow TIDAK mendeteksi GPU. Model berjalan di CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('dataset_split', 'train')\n",
    "val_dir = os.path.join('dataset_split', 'val')\n",
    "test_dir = os.path.join('dataset_split', 'test')\n",
    "\n",
    "# Fungsi untuk menghitung jumlah file per kelas dalam sebuah direktori\n",
    "def count_images_per_class(directory):\n",
    "    return {\n",
    "        cls: len(os.listdir(os.path.join(directory, cls)))\n",
    "        for cls in os.listdir(directory)\n",
    "        if os.path.isdir(os.path.join(directory, cls))\n",
    "    }\n",
    "    \n",
    "# Hitung jumlah gambar per kelas\n",
    "train_counts = count_images_per_class(train_dir)\n",
    "val_counts = count_images_per_class(val_dir)\n",
    "test_counts = count_images_per_class(test_dir)\n",
    "total_gambar = sum(train_counts.values()) + sum(val_counts.values()) + sum(test_counts.values())\n",
    "\n",
    "# Gabungkan ke dalam DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Train': train_counts,\n",
    "    'Validation': val_counts,\n",
    "    'Test': test_counts\n",
    "}).T.fillna(0).astype(int).T  # Transpose agar kelas sebagai indeks\n",
    "\n",
    "\n",
    "print(f\"Total gambar : {total_gambar}\")\n",
    "# Tampilkan sebagai tabel\n",
    "print(\"\\nSebaran Data per Kelas:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 4\n",
    "SEED = 42\n",
    "NUM_CLASSES = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,                # Normalisasi piksel gambar dari 0-255 menjadi 0-1\n",
    "    rotation_range=20,            # Rotasi gambar acak hingga 20 derajat\n",
    "    zoom_range=0.2,               # Zoom acak hingga 20% untuk mensimulasikan perbedaan jarak\n",
    "    width_shift_range=0.2,        # Geser gambar secara horizontal hingga 20% lebar gambar\n",
    "    height_shift_range=0.2,       # Geser gambar secara vertikal hingga 20% tinggi gambar\n",
    "    shear_range=0.15,             # Distorsi gambar secara miring (shear)\n",
    "    horizontal_flip=True,         # Membalik gambar secara horizontal (misalnya daun kiri dan kanan)\n",
    "    brightness_range=[0.8, 1.2],  # Variasi pencahayaan gambar\n",
    "    fill_mode='nearest'           # Isi area kosong hasil transformasi dengan piksel terdekat\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,  # Folder berisi data latih\n",
    "    target_size = IMG_SIZE,         # Ukuran gambar diubah menjadi 224x224\n",
    "    batch_size = BATCH_SIZE,        # Jumlah gambar per batch\n",
    "    class_mode = 'categorical',       # Label dalam format one-hot (karena klasifikasi multi-kelas)\n",
    "    shuffle = True,                   # Acak data untuk melatih model dengan lebih baik\n",
    "    seed = SEED                         # Seed untuk konsistensi hasil saat diacak\n",
    ")\n",
    "\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,  # Folder validasi\n",
    "    target_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False,                  # Tidak diacak agar evaluasi konsisten\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,   # Folder pengujian\n",
    "    target_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False,                  # Tidak diacak agar prediksi bisa dibandingkan langsung\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, GlobalAveragePooling2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from kerastuner.tuners import GridSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Callback untuk progress log\n",
    "class TuningCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, tuner_name):\n",
    "        super().__init__()\n",
    "        self.tuner_name = tuner_name\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metrics_str = \" | \".join([f\"{k}: {v:.4f}\" for k, v in logs.items()])\n",
    "        print(f\"‚ú® {self.tuner_name} - Epoch {epoch + 1} ‚Äî {metrics_str}\")\n",
    "\n",
    "# =========== MODEL BUILDER UNTUK HYPERPARAMETER TUNING ===========\n",
    "def build_model(hp):\n",
    "    # Load pre-trained MobileNetV2 dengan freezing\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=(*IMG_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze semua layer pada base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    \n",
    "    # Tambahkan ConvLayer (opsional)\n",
    "    if hp.Boolean('add_conv_layer', default=True):\n",
    "        filters = hp.Choice('conv_filters', values=[32, 64, 96, 128], default=64)\n",
    "        model.add(Conv2D(filters, (3, 3), activation='relu', padding='same'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # GlobalAveragePooling2D untuk flatten feature map\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    \n",
    "    # Dense layers\n",
    "    dense_units = hp.Choice('dense_units', values=[64, 128, 256, 384, 512], default=128)\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    \n",
    "    # Dropout untuk regularisasi\n",
    "    dropout_rate = hp.Choice('dropout_rate', values=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5], default=0.2)\n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Layer output\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    \n",
    "    # Kompilasi dengan hyperparameter\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-4, 3e-4, 1e-3, 3e-3, 1e-2], default=1e-3)\n",
    "    \n",
    "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== GridSearch TUNER ===========\n",
    "\n",
    "# Buat direktori untuk menyimpan hasil tuning\n",
    "project_dir = \"hyperparameter_tuning_gridsearch_results\"\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "# Buat objek GridSearch tuner\n",
    "tuner = GridSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=15,  # Maksimum epoch untuk setiap trial\n",
    "    directory=project_dir,\n",
    "    project_name=f'mobilenetv2_gridsearch_{int(time.time())}'\n",
    ")\n",
    "\n",
    "# Tampilkan ringkasan search space\n",
    "print(tuner.search_space_summary())\n",
    "\n",
    "# Callbacks untuk setiap trial\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Jalankan pencarian hyperparameter\n",
    "print(\"\\nüöÄ Memulai GridSearch hyperparameter tuning...\")\n",
    "print(\"‚ö†Ô∏è GridSearch akan mencoba semua kombinasi hyperparameter yang mungkin\")\n",
    "print(\"‚ö†Ô∏è Ini bisa memakan waktu yang sangat lama!\")\n",
    "\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,  # Maksimum epoch (akan dihentikan lebih awal oleh early stopping)\n",
    "    callbacks=[early_stopping, reduce_lr, TuningCallback('GridSearch')],\n",
    ")\n",
    "\n",
    "# Tampilkan ringkasan hasil\n",
    "print(\"\\n==== HASIL HYPERPARAMETER TUNING ====\")\n",
    "tuner.results_summary()\n",
    "\n",
    "# Ambil model terbaik\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"\\n==== HYPERPARAMETER TERBAIK ====\")\n",
    "print(f\"Learning rate: {best_hps.get('learning_rate')}\")\n",
    "print(f\"Optimizer: {best_hps.get('optimizer')}\")\n",
    "print(f\"Dropout rate: {best_hps.get('dropout_rate')}\")\n",
    "print(f\"Dense units: {best_hps.get('dense_units')}\")\n",
    "print(f\"Tambah conv layer: {best_hps.get('add_conv_layer')}\")\n",
    "if best_hps.get('add_conv_layer'):\n",
    "    print(f\"Conv filters: {best_hps.get('conv_filters')}\")\n",
    "\n",
    "# Build model terbaik dengan hyperparameter optimal\n",
    "best_model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"\\n==== LATIH MODEL FINAL DENGAN HYPERPARAMETER TERBAIK ====\")\n",
    "# Latih model final dengan seluruh dataset\n",
    "history = best_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        ModelCheckpoint('best_gridsearch_model.keras', save_best_only=True, monitor='val_accuracy'),\n",
    "        reduce_lr\n",
    "    ],\n",
    "    class_weight=class_weights_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Simpan model terbaik\n",
    "best_model.save('final_gridsearch_model.keras')\n",
    "print(\"Model final telah disimpan sebagai 'final_gridsearch_model.keras'\")\n",
    "\n",
    "# Evaluasi model pada test set\n",
    "print(\"\\n==== EVALUASI MODEL PADA TEST SET ====\")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = best_model.evaluate(test_generator)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampilkan visualisasi hyperparameter (opsional, tambahkan jika diperlukan)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualisasi training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('gridsearch_training_history.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training history telah disimpan sebagai 'gridsearch_training_history.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis hasil GridSearch\n",
    "print(\"\\n==== ANALISIS HASIL GRIDSEARCH ====\")\n",
    "print(\"GridSearch telah mencoba semua kombinasi hyperparameter yang mungkin.\")\n",
    "print(\"Ini memberikan hasil yang lebih ekshaustif dibandingkan RandomSearch,\")\n",
    "print(\"tetapi memakan waktu yang jauh lebih lama.\")\n",
    "\n",
    "# Hitung total trials\n",
    "total_trials = len(tuner.oracle.trials)\n",
    "print(f\"\\nTotal trials yang dijalankan: {total_trials}\")\n",
    "\n",
    "# Tampilkan beberapa trial terbaik\n",
    "print(\"\\nTop 5 trials:\")\n",
    "for i, trial in enumerate(tuner.oracle.get_best_trials(5)):\n",
    "    print(f\"{i+1}. Trial {trial.trial_id} - Score: {trial.score:.4f}\")\n",
    "    print(f\"   Hyperparameters: {trial.hyperparameters.values}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}