{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch Hyperparameter Tuning for Batik Classification\n",
    "\n",
    "This notebook implements GridSearch hyperparameter tuning for the batik classification model using Keras Tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Third-party packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import TFSMLayer\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    GlobalAveragePooling2D,\n",
    "    Dense,\n",
    "    Dropout\n",
    ")\n",
    "from tensorflow.keras.applications import InceptionV3, MobileNetV2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import (\n",
    "    ImageDataGenerator,\n",
    "    load_img,\n",
    "    img_to_array\n",
    ")\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    Callback\n",
    ")\n",
    "\n",
    "# Hilangkan warning TensorFlow dan Python\n",
    "import warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TensorFlow mendeteksi GPU (CUDA):\n",
      "  - /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\"✅ TensorFlow mendeteksi GPU (CUDA):\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"  - {gpu.name}\")\n",
    "else:\n",
    "    print(\"⚠️ TensorFlow TIDAK mendeteksi GPU. Model berjalan di CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gambar : 1080\n",
      "\n",
      "Sebaran Data per Kelas:\n",
      "                  Train  Validation  Test\n",
      "Sekar Pijetan        12           3     3\n",
      "Sekar Pacar          12           3     3\n",
      "Gedhangan            12           3     3\n",
      "Sekar Keben          12           3     3\n",
      "Sekar Jali           12           3     3\n",
      "Mawur                12           3     3\n",
      "Sekar Duren          12           3     3\n",
      "Sekar Dlima          12           3     3\n",
      "Jayakirana           12           3     3\n",
      "Cinde Wilis          12           3     3\n",
      "Sekar Blimbing       12           3     3\n",
      "Sekar Ketongkeng     12           3     3\n",
      "Sekar Kemuning       12           3     3\n",
      "Sekar Srengenge      12           3     3\n",
      "Sekar Tebu           12           3     3\n",
      "Sekar Kepel          12           3     3\n",
      "Sekar Lintang        12           3     3\n",
      "Sekar Kenthang       12           3     3\n",
      "Sekar Pala           12           3     3\n",
      "Sekar Mlathi         12           3     3\n",
      "Sekar Randhu         12           3     3\n",
      "Jayakusuma           12           3     3\n",
      "Sekar Manggis        12           3     3\n",
      "Krawitan             12           3     3\n",
      "Sritaman             12           3     3\n",
      "Sekar Mrica          12           3     3\n",
      "Rengganis            12           3     3\n",
      "Sekar Jagung         12           3     3\n",
      "Sekar Nangka         12           3     3\n",
      "Sekar Tanjung        12           3     3\n",
      "Sekar Liring         12           3     3\n",
      "Cakar Ayam           12           3     3\n",
      "Sekar Andhong        12           3     3\n",
      "Klampok Arum         12           3     3\n",
      "Kemukus              12           3     3\n",
      "Sekar Kenikir        12           3     3\n",
      "Sekar Sawo           12           3     3\n",
      "Sekar Kenanga        12           3     3\n",
      "Tanjung Gunung       12           3     3\n",
      "Sekar Gudhe          12           3     3\n",
      "Worawari Rumpuk      12           3     3\n",
      "Sekar Gambir         12           3     3\n",
      "Manggar              12           3     3\n",
      "Sekar Menur          12           3     3\n",
      "Sekar Pudhak         12           3     3\n",
      "Sekar Dangan         12           3     3\n",
      "Kuncup Kanthil       12           3     3\n",
      "Truntum Kurung       12           3     3\n",
      "Arumdalu             12           3     3\n",
      "Sekar Cengkeh        12           3     3\n",
      "Sekar Mindi          12           3     3\n",
      "Sari Mulat           12           3     3\n",
      "Brendhi              12           3     3\n",
      "Sekar Soka           12           3     3\n",
      "Sekar Gayam          12           3     3\n",
      "Sekar Jeruk          12           3     3\n",
      "Sekar Mundhu         12           3     3\n",
      "Kawung Nitik         12           3     3\n",
      "Sekar Srigadhing     12           3     3\n",
      "Sekar Dhuku          12           3     3\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join('../../../../data/splits/dataset_split', 'train')\n",
    "val_dir = os.path.join('../../../../data/splits/dataset_split', 'val')\n",
    "test_dir = os.path.join('../../../../data/splits/dataset_split', 'test')\n",
    "\n",
    "# Fungsi untuk menghitung jumlah file per kelas dalam sebuah direktori\n",
    "def count_images_per_class(directory):\n",
    "    return {\n",
    "        cls: len(os.listdir(os.path.join(directory, cls)))\n",
    "        for cls in os.listdir(directory)\n",
    "        if os.path.isdir(os.path.join(directory, cls))\n",
    "    }\n",
    "    \n",
    "# Hitung jumlah gambar per kelas\n",
    "train_counts = count_images_per_class(train_dir)\n",
    "val_counts = count_images_per_class(val_dir)\n",
    "test_counts = count_images_per_class(test_dir)\n",
    "total_gambar = sum(train_counts.values()) + sum(val_counts.values()) + sum(test_counts.values())\n",
    "\n",
    "# Gabungkan ke dalam DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Train': train_counts,\n",
    "    'Validation': val_counts,\n",
    "    'Test': test_counts\n",
    "}).T.fillna(0).astype(int).T  # Transpose agar kelas sebagai indeks\n",
    "\n",
    "\n",
    "print(f\"Total gambar : {total_gambar}\")\n",
    "# Tampilkan sebagai tabel\n",
    "print(\"\\nSebaran Data per Kelas:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 4\n",
    "SEED = 42\n",
    "NUM_CLASSES = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,                # Normalisasi piksel gambar dari 0-255 menjadi 0-1\n",
    "    rotation_range=20,            # Rotasi gambar acak hingga 20 derajat\n",
    "    zoom_range=0.2,               # Zoom acak hingga 20% untuk mensimulasikan perbedaan jarak\n",
    "    width_shift_range=0.2,        # Geser gambar secara horizontal hingga 20% lebar gambar\n",
    "    height_shift_range=0.2,       # Geser gambar secara vertikal hingga 20% tinggi gambar\n",
    "    shear_range=0.15,             # Distorsi gambar secara miring (shear)\n",
    "    horizontal_flip=True,         # Membalik gambar secara horizontal (misalnya daun kiri dan kanan)\n",
    "    brightness_range=[0.8, 1.2],  # Variasi pencahayaan gambar\n",
    "    fill_mode='nearest'           # Isi area kosong hasil transformasi dengan piksel terdekat\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 720 images belonging to 60 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 images belonging to 60 classes.\n",
      "Found 180 images belonging to 60 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,  # Folder berisi data latih\n",
    "    target_size = IMG_SIZE,         # Ukuran gambar diubah menjadi 224x224\n",
    "    batch_size = BATCH_SIZE,        # Jumlah gambar per batch\n",
    "    class_mode = 'categorical',       # Label dalam format one-hot (karena klasifikasi multi-kelas)\n",
    "    shuffle = True,                   # Acak data untuk melatih model dengan lebih baik\n",
    "    seed = SEED                         # Seed untuk konsistensi hasil saat diacak\n",
    ")\n",
    "\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,  # Folder validasi\n",
    "    target_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False,                  # Tidak diacak agar evaluasi konsisten\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,   # Folder pengujian\n",
    "    target_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False,                  # Tidak diacak agar prediksi bisa dibandingkan langsung\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, GlobalAveragePooling2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from kerastuner.tuners import GridSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Callback untuk progress log\n",
    "class TuningCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, tuner_name):\n",
    "        super().__init__()\n",
    "        self.tuner_name = tuner_name\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metrics_str = \" | \".join([f\"{k}: {v:.4f}\" for k, v in logs.items()])\n",
    "        print(f\"✨ {self.tuner_name} - Epoch {epoch + 1} — {metrics_str}\")\n",
    "\n",
    "# =========== MODEL BUILDER UNTUK HYPERPARAMETER TUNING ===========\n",
    "def build_model(hp):\n",
    "    # Load pre-trained MobileNetV2 dengan freezing\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=(*IMG_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze semua layer pada base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    \n",
    "    # Tambahkan ConvLayer (opsional)\n",
    "    if hp.Boolean('add_conv_layer', default=True):\n",
    "        filters = hp.Choice('conv_filters', values=[32, 64], default=64)\n",
    "        model.add(Conv2D(filters, (3, 3), activation='relu', padding='same'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # GlobalAveragePooling2D untuk flatten feature map\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    \n",
    "    # Dense layers\n",
    "    dense_units = hp.Choice('dense_units', values=[64, 128], default=128)\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    \n",
    "    # Dropout untuk regularisasi\n",
    "    dropout_rate = hp.Choice('dropout_rate', values=[0.2, 0.3], default=0.2)\n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Layer output\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    \n",
    "    # Kompilasi dengan hyperparameter\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-4, 1e-3], default=1e-3)\n",
    "    \n",
    "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 Complete [00h 02m 00s]\n",
      "val_accuracy: 0.9833333492279053\n",
      "\n",
      "Best val_accuracy So Far: 0.9833333492279053\n",
      "Total elapsed time: 00h 25m 45s\n",
      "\n",
      "Search: Running Trial #9\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "True              |True              |add_conv_layer\n",
      "64                |64                |conv_filters\n",
      "128               |128               |dense_units\n",
      "0.2               |0.2               |dropout_rate\n",
      "0.0003            |0.001             |learning_rate\n",
      "sgd               |sgd               |optimizer\n",
      "\n",
      "Epoch 1/30\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.0317 - loss: 4.1395[GridSearch] Epoch 1 - loss: 3.9410, accuracy: 0.0653, val_loss: 3.2377, val_accuracy: 0.2500\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 53ms/step - accuracy: 0.0319 - loss: 4.1384 - val_accuracy: 0.2500 - val_loss: 3.2377 - learning_rate: 3.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2487 - loss: 3.1014[GridSearch] Epoch 2 - loss: 2.8845, accuracy: 0.3111, val_loss: 1.7796, val_accuracy: 0.6056\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.2491 - loss: 3.1002 - val_accuracy: 0.6056 - val_loss: 1.7796 - learning_rate: 3.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m179/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5536 - loss: 1.8503[GridSearch] Epoch 3 - loss: 1.6582, accuracy: 0.5861, val_loss: 0.8959, val_accuracy: 0.8278\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.5540 - loss: 1.8482 - val_accuracy: 0.8278 - val_loss: 0.8959 - learning_rate: 3.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7141 - loss: 1.0448"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m⚠️ Ini bisa memakan waktu yang sangat lama!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Bagian ini sudah benar. 'epochs' ditempatkan di sini.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[43mtuner\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Setiap trial akan dilatih hingga 30 epoch (atau dihentikan lebih awal)\u001b[39;49;00m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTuningCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGridSearch\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Tampilkan ringkasan hasil\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m==== HASIL HYPERPARAMETER TUNING ====\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[39m, in \u001b[36mBaseTuner.search\u001b[39m\u001b[34m(self, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_begin(trial)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_end(trial)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.on_search_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[39m, in \u001b[36mBaseTuner._try_run_and_update_trial\u001b[39m\u001b[34m(self, trial, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, *fit_args, **fit_kwargs):\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m         trial.status = trial_module.TrialStatus.COMPLETED\n\u001b[32m    276\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[39m, in \u001b[36mBaseTuner._run_and_update_trial\u001b[39m\u001b[34m(self, trial, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, *fit_args, **fit_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[32m    241\u001b[39m         \u001b[38;5;28mself\u001b[39m.oracle.objective.name\n\u001b[32m    242\u001b[39m     ):\n\u001b[32m    243\u001b[39m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[32m    244\u001b[39m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[32m    245\u001b[39m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[32m    246\u001b[39m         warnings.warn(\n\u001b[32m    247\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe use case of calling \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    254\u001b[39m             stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    255\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[39m, in \u001b[36mTuner.run_trial\u001b[39m\u001b[34m(self, trial, *args, **kwargs)\u001b[39m\n\u001b[32m    312\u001b[39m     callbacks.append(model_checkpoint)\n\u001b[32m    313\u001b[39m     copied_kwargs[\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m] = callbacks\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     obj_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m     histories.append(obj_value)\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[39m, in \u001b[36mTuner._build_and_fit_model\u001b[39m\u001b[34m(self, trial, *args, **kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m hp = trial.hyperparameters\n\u001b[32m    232\u001b[39m model = \u001b[38;5;28mself\u001b[39m._try_build(hp)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.config.multi_backend():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[39m, in \u001b[36mHyperModel.fit\u001b[39m\u001b[34m(self, hp, model, *args, **kwargs)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, *args, **kwargs):\n\u001b[32m    126\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[32m    127\u001b[39m \n\u001b[32m    128\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    147\u001b[39m \u001b[33;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:401\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_eval_epoch_iterator\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    391\u001b[39m     \u001b[38;5;28mself\u001b[39m._eval_epoch_iterator = TFEpochIterator(\n\u001b[32m    392\u001b[39m         x=val_x,\n\u001b[32m    393\u001b[39m         y=val_y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    399\u001b[39m         shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    400\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m val_logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m val_logs = {\n\u001b[32m    412\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mval_\u001b[39m\u001b[33m\"\u001b[39m + name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs.items()\n\u001b[32m    413\u001b[39m }\n\u001b[32m    414\u001b[39m epoch_logs.update(val_logs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:489\u001b[39m, in \u001b[36mTensorFlowTrainer.evaluate\u001b[39m\u001b[34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    488\u001b[39m     callbacks.on_test_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    490\u001b[39m     callbacks.on_test_batch_end(step, logs)\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_evaluating:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# =========== GridSearch TUNER ===========\n",
    "\n",
    "# Buat direktori untuk menyimpan hasil tuning\n",
    "project_dir = \"hyperparameter_tuning_gridsearch_results\"\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "# Buat objek GridSearch tuner\n",
    "# PERBAIKAN: Hapus argumen 'max_epochs' dari sini.\n",
    "tuner = GridSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    directory=project_dir,\n",
    "    project_name=f'mobilenetv2_gridsearch_{int(time.time())}'\n",
    ")\n",
    "\n",
    "# Tampilkan ringkasan search space\n",
    "print(\"===== SEARCH SPACE SUMMARY =====\")\n",
    "tuner.search_space_summary()\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# Callbacks untuk setiap trial\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Definisikan TuningCallback Anda jika belum ada\n",
    "class TuningCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, tuner_name):\n",
    "        super().__init__()\n",
    "        self.tuner_name = tuner_name\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"[{self.tuner_name}] Epoch {epoch+1} - loss: {logs['loss']:.4f}, accuracy: {logs['accuracy']:.4f}, val_loss: {logs['val_loss']:.4f}, val_accuracy: {logs['val_accuracy']:.4f}\")\n",
    "\n",
    "# Jalankan pencarian hyperparameter\n",
    "print(\"\\n🚀 Memulai GridSearch hyperparameter tuning...\")\n",
    "print(\"⚠️ GridSearch akan mencoba semua kombinasi hyperparameter yang mungkin.\")\n",
    "print(\"⚠️ Ini bisa memakan waktu yang sangat lama!\")\n",
    "\n",
    "# Bagian ini sudah benar. 'epochs' ditempatkan di sini.\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,  # Setiap trial akan dilatih hingga 30 epoch (atau dihentikan lebih awal)\n",
    "    callbacks=[early_stopping, reduce_lr, TuningCallback('GridSearch')],\n",
    ")\n",
    "\n",
    "# Tampilkan ringkasan hasil\n",
    "print(\"\\n==== HASIL HYPERPARAMETER TUNING ====\")\n",
    "tuner.results_summary()\n",
    "\n",
    "# Ambil model terbaik\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"\\n==== HYPERPARAMETER TERBAIK ====\")\n",
    "print(f\"Learning rate: {best_hps.get('learning_rate')}\")\n",
    "print(f\"Optimizer: {best_hps.get('optimizer')}\")\n",
    "print(f\"Dropout rate: {best_hps.get('dropout_rate')}\")\n",
    "print(f\"Dense units: {best_hps.get('dense_units')}\")\n",
    "print(f\"Tambah conv layer: {best_hps.get('add_conv_layer')}\")\n",
    "if best_hps.get('add_conv_layer'):\n",
    "    print(f\"Conv filters: {best_hps.get('conv_filters')}\")\n",
    "\n",
    "# Build model terbaik dengan hyperparameter optimal\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "print(\"\\nModel terbaik berhasil dibuat dengan hyperparameter optimal.\")\n",
    "# Build model terbaik dengan hyperparameter optimal\n",
    "best_model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== LATIH MODEL FINAL DENGAN HYPERPARAMETER TERBAIK ====\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m==== LATIH MODEL FINAL DENGAN HYPERPARAMETER TERBAIK ====\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Latih model final dengan seluruh dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m history = \u001b[43mbest_model\u001b[49m.fit(\n\u001b[32m     12\u001b[39m     train_generator,\n\u001b[32m     13\u001b[39m     validation_data=val_generator,\n\u001b[32m     14\u001b[39m     epochs=\u001b[32m30\u001b[39m,\n\u001b[32m     15\u001b[39m     callbacks=[\n\u001b[32m     16\u001b[39m         early_stopping,\n\u001b[32m     17\u001b[39m         ModelCheckpoint(\u001b[33m'\u001b[39m\u001b[33mbest_gridsearch_model.keras\u001b[39m\u001b[33m'\u001b[39m, save_best_only=\u001b[38;5;28;01mTrue\u001b[39;00m, monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     18\u001b[39m         reduce_lr\n\u001b[32m     19\u001b[39m     ],\n\u001b[32m     20\u001b[39m     class_weight=class_weights_dict,\n\u001b[32m     21\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     22\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Simpan model terbaik\u001b[39;00m\n\u001b[32m     25\u001b[39m best_model.save(\u001b[33m'\u001b[39m\u001b[33mfinal_gridsearch_model.keras\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Hitung class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"\\n==== LATIH MODEL FINAL DENGAN HYPERPARAMETER TERBAIK ====\")\n",
    "# Latih model final dengan seluruh dataset\n",
    "history = best_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        ModelCheckpoint('best_gridsearch_model.keras', save_best_only=True, monitor='val_accuracy'),\n",
    "        reduce_lr\n",
    "    ],\n",
    "    class_weight=class_weights_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Simpan model terbaik\n",
    "best_model.save('final_gridsearch_model.keras')\n",
    "print(\"Model final telah disimpan sebagai 'final_gridsearch_model.keras'\")\n",
    "\n",
    "# Evaluasi model pada test set\n",
    "print(\"\\n==== EVALUASI MODEL PADA TEST SET ====\")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = best_model.evaluate(test_generator)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized arguments ['max_epochs'] for `BaseTuner.__init__()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 8\u001b[39m\n",
      "\u001b[32m      5\u001b[39m os.makedirs(project_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Buat objek GridSearch tuner\u001b[39;00m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m tuner = \u001b[43mGridSearch\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuild_model\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval_accuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Maksimum epoch untuk setiap trial\u001b[39;49;00m\n",
      "\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject_dir\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmobilenetv2_gridsearch_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\n",
      "\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Tampilkan ringkasan search space\u001b[39;00m\n",
      "\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(tuner.search_space_summary())\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras_tuner/src/tuners/gridsearch.py:419\u001b[39m, in \u001b[36mGridSearch.__init__\u001b[39m\u001b[34m(self, hypermodel, objective, max_trials, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[39m\n",
      "\u001b[32m    408\u001b[39m \u001b[38;5;28mself\u001b[39m.seed = seed\n",
      "\u001b[32m    409\u001b[39m oracle = GridSearchOracle(\n",
      "\u001b[32m    410\u001b[39m     objective=objective,\n",
      "\u001b[32m    411\u001b[39m     max_trials=max_trials,\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    417\u001b[39m     max_consecutive_failed_trials=max_consecutive_failed_trials,\n",
      "\u001b[32m    418\u001b[39m )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:122\u001b[39m, in \u001b[36mTuner.__init__\u001b[39m\u001b[34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001b[39m\n",
      "\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hypermodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.run_trial \u001b[38;5;129;01mis\u001b[39;00m Tuner.run_trial:\n",
      "\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[32m    116\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    117\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`hypermodel` if the user defines the search space in \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    118\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    119\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33musing a `HyperModel` instance.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    120\u001b[39m     )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43moracle\u001b[49m\u001b[43m=\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    130\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    132\u001b[39m \u001b[38;5;28mself\u001b[39m.max_model_size = max_model_size\n",
      "\u001b[32m    133\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer = optimizer\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:107\u001b[39m, in \u001b[36mBaseTuner.__init__\u001b[39m\u001b[34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001b[39m\n",
      "\u001b[32m    104\u001b[39m \u001b[38;5;28mself\u001b[39m.logger = logger\n",
      "\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) > \u001b[32m0\u001b[39m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[32m    108\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    109\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfor `BaseTuner.__init__()`.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    110\u001b[39m     )\n",
      "\u001b[32m    112\u001b[39m \u001b[38;5;28mself\u001b[39m.oracle = oracle\n",
      "\u001b[32m    113\u001b[39m \u001b[38;5;28mself\u001b[39m.hypermodel = hm_module.get_hypermodel(hypermodel)\n",
      "\n",
      "\u001b[31mValueError\u001b[39m: Unrecognized arguments ['max_epochs'] for `BaseTuner.__init__()`."
     ]
    }
   ],
   "source": [
    "# =========== GridSearch TUNER ===========\n",
    "\n",
    "# Buat direktori untuk menyimpan hasil tuning\n",
    "project_dir = \"hyperparameter_tuning_gridsearch_results\"\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "# Buat objek GridSearch tuner\n",
    "tuner = GridSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=15,  # Maksimum epoch untuk setiap trial\n",
    "    directory=project_dir,\n",
    "    project_name=f'mobilenetv2_gridsearch_{int(time.time())}'\n",
    ")\n",
    "\n",
    "# Tampilkan ringkasan search space\n",
    "print(tuner.search_space_summary())\n",
    "\n",
    "# Callbacks untuk setiap trial\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Jalankan pencarian hyperparameter\n",
    "print(\"\\n🚀 Memulai GridSearch hyperparameter tuning...\")\n",
    "print(\"⚠️ GridSearch akan mencoba semua kombinasi hyperparameter yang mungkin\")\n",
    "print(\"⚠️ Ini bisa memakan waktu yang sangat lama!\")\n",
    "\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,  # Maksimum epoch (akan dihentikan lebih awal oleh early stopping)\n",
    "    callbacks=[early_stopping, reduce_lr, TuningCallback('GridSearch')],\n",
    ")\n",
    "\n",
    "# Tampilkan ringkasan hasil\n",
    "print(\"\\n==== HASIL HYPERPARAMETER TUNING ====\")\n",
    "tuner.results_summary()\n",
    "\n",
    "# Ambil model terbaik\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"\\n==== HYPERPARAMETER TERBAIK ====\")\n",
    "print(f\"Learning rate: {best_hps.get('learning_rate')}\")\n",
    "print(f\"Optimizer: {best_hps.get('optimizer')}\")\n",
    "print(f\"Dropout rate: {best_hps.get('dropout_rate')}\")\n",
    "print(f\"Dense units: {best_hps.get('dense_units')}\")\n",
    "print(f\"Tambah conv layer: {best_hps.get('add_conv_layer')}\")\n",
    "if best_hps.get('add_conv_layer'):\n",
    "    print(f\"Conv filters: {best_hps.get('conv_filters')}\")\n",
    "\n",
    "# Build model terbaik dengan hyperparameter optimal\n",
    "best_model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized arguments ['max_epochs'] for `BaseTuner.__init__()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 8\u001b[39m\n",
      "\u001b[32m      5\u001b[39m os.makedirs(project_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Buat objek GridSearch tuner\u001b[39;00m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m tuner = \u001b[43mGridSearch\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuild_model\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval_accuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Maksimum epoch untuk setiap trial\u001b[39;49;00m\n",
      "\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject_dir\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmobilenetv2_gridsearch_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\n",
      "\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Tampilkan ringkasan search space\u001b[39;00m\n",
      "\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(tuner.search_space_summary())\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras_tuner/src/tuners/gridsearch.py:419\u001b[39m, in \u001b[36mGridSearch.__init__\u001b[39m\u001b[34m(self, hypermodel, objective, max_trials, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[39m\n",
      "\u001b[32m    408\u001b[39m \u001b[38;5;28mself\u001b[39m.seed = seed\n",
      "\u001b[32m    409\u001b[39m oracle = GridSearchOracle(\n",
      "\u001b[32m    410\u001b[39m     objective=objective,\n",
      "\u001b[32m    411\u001b[39m     max_trials=max_trials,\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    417\u001b[39m     max_consecutive_failed_trials=max_consecutive_failed_trials,\n",
      "\u001b[32m    418\u001b[39m )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:122\u001b[39m, in \u001b[36mTuner.__init__\u001b[39m\u001b[34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001b[39m\n",
      "\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hypermodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.run_trial \u001b[38;5;129;01mis\u001b[39;00m Tuner.run_trial:\n",
      "\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[32m    116\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    117\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`hypermodel` if the user defines the search space in \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    118\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    119\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33musing a `HyperModel` instance.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    120\u001b[39m     )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43moracle\u001b[49m\u001b[43m=\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    130\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    132\u001b[39m \u001b[38;5;28mself\u001b[39m.max_model_size = max_model_size\n",
      "\u001b[32m    133\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer = optimizer\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:107\u001b[39m, in \u001b[36mBaseTuner.__init__\u001b[39m\u001b[34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001b[39m\n",
      "\u001b[32m    104\u001b[39m \u001b[38;5;28mself\u001b[39m.logger = logger\n",
      "\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) > \u001b[32m0\u001b[39m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[32m    108\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    109\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfor `BaseTuner.__init__()`.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    110\u001b[39m     )\n",
      "\u001b[32m    112\u001b[39m \u001b[38;5;28mself\u001b[39m.oracle = oracle\n",
      "\u001b[32m    113\u001b[39m \u001b[38;5;28mself\u001b[39m.hypermodel = hm_module.get_hypermodel(hypermodel)\n",
      "\n",
      "\u001b[31mValueError\u001b[39m: Unrecognized arguments ['max_epochs'] for `BaseTuner.__init__()`."
     ]
    }
   ],
   "source": [
    "# =========== GridSearch TUNER ===========\n",
    "\n",
    "# Buat direktori untuk menyimpan hasil tuning\n",
    "project_dir = \"hyperparameter_tuning_gridsearch_results\"\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "# Buat objek GridSearch tuner\n",
    "tuner = GridSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=15,  # Maksimum epoch untuk setiap trial\n",
    "    directory=project_dir,\n",
    "    project_name=f'mobilenetv2_gridsearch_{int(time.time())}'\n",
    ")\n",
    "\n",
    "# Tampilkan ringkasan search space\n",
    "print(tuner.search_space_summary())\n",
    "\n",
    "# Callbacks untuk setiap trial\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Jalankan pencarian hyperparameter\n",
    "print(\"\\n🚀 Memulai GridSearch hyperparameter tuning...\")\n",
    "print(\"⚠️ GridSearch akan mencoba semua kombinasi hyperparameter yang mungkin\")\n",
    "print(\"⚠️ Ini bisa memakan waktu yang sangat lama!\")\n",
    "\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,  # Maksimum epoch (akan dihentikan lebih awal oleh early stopping)\n",
    "    callbacks=[early_stopping, reduce_lr, TuningCallback('GridSearch')],\n",
    ")\n",
    "\n",
    "# Tampilkan ringkasan hasil\n",
    "print(\"\\n==== HASIL HYPERPARAMETER TUNING ====\")\n",
    "tuner.results_summary()\n",
    "\n",
    "# Ambil model terbaik\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"\\n==== HYPERPARAMETER TERBAIK ====\")\n",
    "print(f\"Learning rate: {best_hps.get('learning_rate')}\")\n",
    "print(f\"Optimizer: {best_hps.get('optimizer')}\")\n",
    "print(f\"Dropout rate: {best_hps.get('dropout_rate')}\")\n",
    "print(f\"Dense units: {best_hps.get('dense_units')}\")\n",
    "print(f\"Tambah conv layer: {best_hps.get('add_conv_layer')}\")\n",
    "if best_hps.get('add_conv_layer'):\n",
    "    print(f\"Conv filters: {best_hps.get('conv_filters')}\")\n",
    "\n",
    "# Build model terbaik dengan hyperparameter optimal\n",
    "best_model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized arguments ['max_epochs'] for `BaseTuner.__init__()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 8\u001b[39m\n",
      "\u001b[32m      5\u001b[39m os.makedirs(project_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Buat objek GridSearch tuner\u001b[39;00m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m tuner = \u001b[43mGridSearch\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuild_model\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval_accuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Maksimum epoch untuk setiap trial\u001b[39;49;00m\n",
      "\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject_dir\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmobilenetv2_gridsearch_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\n",
      "\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Tampilkan ringkasan search space\u001b[39;00m\n",
      "\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(tuner.search_space_summary())\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras_tuner/src/tuners/gridsearch.py:419\u001b[39m, in \u001b[36mGridSearch.__init__\u001b[39m\u001b[34m(self, hypermodel, objective, max_trials, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[39m\n",
      "\u001b[32m    408\u001b[39m \u001b[38;5;28mself\u001b[39m.seed = seed\n",
      "\u001b[32m    409\u001b[39m oracle = GridSearchOracle(\n",
      "\u001b[32m    410\u001b[39m     objective=objective,\n",
      "\u001b[32m    411\u001b[39m     max_trials=max_trials,\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    417\u001b[39m     max_consecutive_failed_trials=max_consecutive_failed_trials,\n",
      "\u001b[32m    418\u001b[39m )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:122\u001b[39m, in \u001b[36mTuner.__init__\u001b[39m\u001b[34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001b[39m\n",
      "\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hypermodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.run_trial \u001b[38;5;129;01mis\u001b[39;00m Tuner.run_trial:\n",
      "\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[32m    116\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    117\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`hypermodel` if the user defines the search space in \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    118\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    119\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33musing a `HyperModel` instance.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    120\u001b[39m     )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43moracle\u001b[49m\u001b[43m=\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    130\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    132\u001b[39m \u001b[38;5;28mself\u001b[39m.max_model_size = max_model_size\n",
      "\u001b[32m    133\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer = optimizer\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Batik-Final/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:107\u001b[39m, in \u001b[36mBaseTuner.__init__\u001b[39m\u001b[34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001b[39m\n",
      "\u001b[32m    104\u001b[39m \u001b[38;5;28mself\u001b[39m.logger = logger\n",
      "\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) > \u001b[32m0\u001b[39m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[32m    108\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    109\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfor `BaseTuner.__init__()`.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    110\u001b[39m     )\n",
      "\u001b[32m    112\u001b[39m \u001b[38;5;28mself\u001b[39m.oracle = oracle\n",
      "\u001b[32m    113\u001b[39m \u001b[38;5;28mself\u001b[39m.hypermodel = hm_module.get_hypermodel(hypermodel)\n",
      "\n",
      "\u001b[31mValueError\u001b[39m: Unrecognized arguments ['max_epochs'] for `BaseTuner.__init__()`."
     ]
    }
   ],
   "source": [
    "# =========== GridSearch TUNER ===========\n",
    "\n",
    "# Buat direktori untuk menyimpan hasil tuning\n",
    "project_dir = \"hyperparameter_tuning_gridsearch_results\"\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "# Buat objek GridSearch tuner\n",
    "tuner = GridSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=15,  # Maksimum epoch untuk setiap trial\n",
    "    directory=project_dir,\n",
    "    project_name=f'mobilenetv2_gridsearch_{int(time.time())}'\n",
    ")\n",
    "\n",
    "# Tampilkan ringkasan search space\n",
    "print(tuner.search_space_summary())\n",
    "\n",
    "# Callbacks untuk setiap trial\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Jalankan pencarian hyperparameter\n",
    "print(\"\\n🚀 Memulai GridSearch hyperparameter tuning...\")\n",
    "print(\"⚠️ GridSearch akan mencoba semua kombinasi hyperparameter yang mungkin\")\n",
    "print(\"⚠️ Ini bisa memakan waktu yang sangat lama!\")\n",
    "\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,  # Maksimum epoch (akan dihentikan lebih awal oleh early stopping)\n",
    "    callbacks=[early_stopping, reduce_lr, TuningCallback('GridSearch')],\n",
    ")\n",
    "\n",
    "# Tampilkan ringkasan hasil\n",
    "print(\"\\n==== HASIL HYPERPARAMETER TUNING ====\")\n",
    "tuner.results_summary()\n",
    "\n",
    "# Ambil model terbaik\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"\\n==== HYPERPARAMETER TERBAIK ====\")\n",
    "print(f\"Learning rate: {best_hps.get('learning_rate')}\")\n",
    "print(f\"Optimizer: {best_hps.get('optimizer')}\")\n",
    "print(f\"Dropout rate: {best_hps.get('dropout_rate')}\")\n",
    "print(f\"Dense units: {best_hps.get('dense_units')}\")\n",
    "print(f\"Tambah conv layer: {best_hps.get('add_conv_layer')}\")\n",
    "if best_hps.get('add_conv_layer'):\n",
    "    print(f\"Conv filters: {best_hps.get('conv_filters')}\")\n",
    "\n",
    "# Build model terbaik dengan hyperparameter optimal\n",
    "best_model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m4\u001b[39m))\n\u001b[32m      7\u001b[39m plt.subplot(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m plt.plot(\u001b[43mhistory\u001b[49m.history[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      9\u001b[39m plt.plot(history.history[\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     10\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mModel Accuracy\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tampilkan visualisasi hyperparameter (opsional, tambahkan jika diperlukan)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualisasi training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('gridsearch_training_history.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training history telah disimpan sebagai 'gridsearch_training_history.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis hasil GridSearch\n",
    "print(\"\\n==== ANALISIS HASIL GRIDSEARCH ====\")\n",
    "print(\"GridSearch telah mencoba semua kombinasi hyperparameter yang mungkin.\")\n",
    "print(\"Ini memberikan hasil yang lebih ekshaustif dibandingkan RandomSearch,\")\n",
    "print(\"tetapi memakan waktu yang jauh lebih lama.\")\n",
    "\n",
    "# Hitung total trials\n",
    "total_trials = len(tuner.oracle.trials)\n",
    "print(f\"\\nTotal trials yang dijalankan: {total_trials}\")\n",
    "\n",
    "# Tampilkan beberapa trial terbaik\n",
    "print(\"\\nTop 5 trials:\")\n",
    "for i, trial in enumerate(tuner.oracle.get_best_trials(5)):\n",
    "    print(f\"{i+1}. Trial {trial.trial_id} - Score: {trial.score:.4f}\")\n",
    "    print(f\"   Hyperparameters: {trial.hyperparameters.values}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
